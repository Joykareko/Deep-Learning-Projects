{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Dataset using torch.",
      "provenance": [],
      "authorship_tag": "ABX9TyO/iopNuNSM4ET8caH7wrqd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joykareko/Deep-Learning-Projects/blob/main/MNIST_Dataset_using_torch_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ],
      "metadata": {
        "id": "ZjgG-ZYq_oW8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xetxu-a4_lao"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, cost, optimizer, epoch):\n",
        "    model.train()\n",
        "    for e in range(epoch):\n",
        "        running_loss=0\n",
        "        correct=0\n",
        "        for data, target in train_loader:   #iterates through batches\n",
        "            data = data.view(data.shape[0], -1)   #reshapes the data\n",
        "            optimizer.zero_grad()    #resets gradients for new batch\n",
        "            pred = model(data)           #runs forward pass\n",
        "            loss = cost(pred, target)    #calculates loss\n",
        "            running_loss+=loss\n",
        "            loss.backward()   #calculates gradients for model\n",
        "            optimizer.step()   #calculates weights\n",
        "            pred=pred.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        print(f\"Epoch {e}: Loss {running_loss/len(train_loader.dataset)}, Accuracy {100*(correct/len(train_loader.dataset))}%\")\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data = data.view(data.shape[0], -1)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    print(f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} = {100*(correct/len(test_loader.dataset))}%)')\n",
        "    #TODO: Add code here to test the accuracy of your model\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "U5khvuxT_3O4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    # Build a feed-forward network\n",
        "    input_size = 784\n",
        "    output_size = 10\n",
        "    model = nn.Sequential(nn.Linear(input_size, 128),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Linear(128, 64),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Linear(64, output_size),\n",
        "                          nn.LogSoftmax(dim=1))\n",
        "\n",
        "    return model\n",
        "    #TODO: Add your model code here. You can use code from previous exercises\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "lMql6GKU_8IQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Create your Data Transforms\n",
        "\n",
        "training_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  #performs data augmentation(adding extra files to prevent overfitting)\n",
        "    transforms.ToTensor(),                   #creates a tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  #normalizes the data so that the mean is zero.\n",
        "    ])\n",
        "\n",
        "testing_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "ndn0Sbf7AAkb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Download and create loaders for your data\n",
        "# Set Hyperparameters\n",
        "batch_size = 64 #number of samples\n",
        "epoch = 5   #number of training through the whole dataset\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('data/', download=True, train=True, transform=training_transform)\n",
        "testset = datasets.MNIST('data/', download=True, train=False, transform=testing_transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "model=create_model()\n",
        "\n",
        "cost = nn.NLLLoss()  #helps us know how well the model is training\n",
        "#TODO: Add your cost function here. You can use code from previous exercises\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)   #helps us specify how the model will train\n",
        "#TODO: Add your optimizer here. You can use code from previous exercises\n",
        "\n",
        "\n",
        "train(model, train_loader, cost, optimizer, epoch)\n",
        "test(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdkhErAWAEtw",
        "outputId": "47255f95-297f-48ed-b92c-8984948519ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 0.01648799702525139, Accuracy 68.95%\n",
            "Epoch 1: Loss 0.007829088717699051, Accuracy 84.13833333333334%\n",
            "Epoch 2: Loss 0.0064287856221199036, Accuracy 87.16333333333334%\n",
            "Epoch 3: Loss 0.005389326252043247, Accuracy 89.53666666666666%\n",
            "Epoch 4: Loss 0.004581128247082233, Accuracy 91.33%\n",
            "Test set: Accuracy: 9200/10000 = 92.0%)\n"
          ]
        }
      ]
    }
  ]
}